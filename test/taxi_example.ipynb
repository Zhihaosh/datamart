{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, random, os, json\n",
    "sys.path.append(sys.path.append(os.path.join(os.getcwd(), '..')))\n",
    "from datamart.augment import Augment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_index = \"datamart_all\"\n",
    "\n",
    "augment = Augment(es_index=es_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a sub set about taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    d3mIndex tpep_pickup_datetime  num_pickups\n0          0  2018-01-01 00:00:00           67\n1          1  2018-01-01 01:00:00            8\n2          2  2018-01-01 02:00:00            0\n3          3  2018-01-01 03:00:00            0\n4          4  2018-01-01 04:00:00            7\n5          5  2018-01-01 05:00:00           10\n6          6  2018-01-01 06:00:00            9\n7          7  2018-01-01 07:00:00           28\n8          8  2018-01-01 08:00:00          157\n9          9  2018-01-01 09:00:00          259\n10        10  2018-01-01 10:00:00          301\n11        11  2018-01-01 11:00:00          436\n12        12  2018-01-01 12:00:00          369\n13        13  2018-01-01 13:00:00          347\n14        14  2018-01-01 14:00:00          494\n15        15  2018-01-01 15:00:00          544\n16        16  2018-01-01 16:00:00          467\n17        17  2018-01-01 17:00:00          690\n18        18  2018-01-01 18:00:00          461\n19        19  2018-01-01 19:00:00          465\n20        20  2018-01-01 20:00:00          451\n21        21  2018-01-01 21:00:00          556\n22        22  2018-01-01 22:00:00          570\n23        23  2018-01-01 23:00:00          499\n24        24  2018-01-02 00:00:00          399\n25        25  2018-01-02 01:00:00           13\n26        26  2018-01-02 02:00:00           17\n27        27  2018-01-02 03:00:00            1\n28        28  2018-01-02 04:00:00            1\n29        29  2018-01-02 05:00:00            8\n30        30  2018-01-02 06:00:00           18\n31        31  2018-01-02 07:00:00          203\n32        32  2018-01-02 08:00:00          359\n33        33  2018-01-02 09:00:00          641\n34        34  2018-01-02 10:00:00          447\n35        35  2018-01-02 11:00:00          598\n36        36  2018-01-02 12:00:00          425\n37        37  2018-01-02 13:00:00          475\n38        38  2018-01-02 14:00:00          572\n39        39  2018-01-02 15:00:00          432\n40        40  2018-01-02 16:00:00          526\n41        41  2018-01-02 17:00:00          577\n42        42  2018-01-02 18:00:00          573\n43        43  2018-01-02 19:00:00          537\n44        44  2018-01-02 20:00:00          464\n45        45  2018-01-02 21:00:00          549\n46        46  2018-01-02 22:00:00          491\n47        47  2018-01-02 23:00:00          394\n"
     ]
    }
   ],
   "source": [
    "old_df = pd.read_csv(\"./test/taxi.csv\")\n",
    "print(old_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "### Is there any dataset in Datamart has named_entity new york and is related to wind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "metadatas = augment.query_by_key_value_pairs(key_value_pairs=[\n",
    "    (\"variables.named_entity\", \"new york\"),\n",
    "    (\"description\", \"wind\")\n",
    "])\n",
    "print(len(metadatas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "### Is there any dataset in Datamart has temporal coverage and it covers the range between `start` and `end`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12267\n"
     ]
    }
   ],
   "source": [
    "metadatas_satisfy_temporal = augment.query_by_temporal_coverage(\n",
    "    start=\"2018-01-01 00:00:00\",\n",
    "    end=\"2018-01-03 00:00:00\"\n",
    ")\n",
    "print(len(metadatas_satisfy_temporal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the intersection of Query 1 and 2. Print datamart_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125480000, 124480000, 124620000, 124600000, 125530000, 124530000, 125150000, 125450000, 125030000]\n"
     ]
    }
   ],
   "source": [
    "intersections = augment.get_metadata_intersection(metadatas, metadatas_satisfy_temporal)\n",
    "print([x[\"_source\"][\"datamart_id\"] for x in intersections])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materialize them with their metadata. Constrain should come from UI, will have UI for user to form such constrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Direction of fastest 2-minute wind (degrees)========\n                   date          stationid      city  WDF2\n0   2018-01-01T00:00:00  GHCND:USW00014732  new york   320\n1   2018-01-01T00:00:00  GHCND:USW00014734  new york   330\n2   2018-01-01T00:00:00  GHCND:USW00054743  new york   320\n3   2018-01-01T00:00:00  GHCND:USW00054787  new york   330\n4   2018-01-01T00:00:00  GHCND:USW00094728  new york   300\n5   2018-01-01T00:00:00  GHCND:USW00094741  new york   310\n6   2018-01-01T00:00:00  GHCND:USW00094745  new york   290\n7   2018-01-01T00:00:00  GHCND:USW00094789  new york   310\n8   2018-01-02T00:00:00  GHCND:USW00014732  new york   270\n9   2018-01-02T00:00:00  GHCND:USW00014734  new york   260\n10  2018-01-02T00:00:00  GHCND:USW00054743  new york   290\n11  2018-01-02T00:00:00  GHCND:USW00054787  new york   250\n12  2018-01-02T00:00:00  GHCND:USW00094728  new york   260\n13  2018-01-02T00:00:00  GHCND:USW00094741  new york   300\n14  2018-01-02T00:00:00  GHCND:USW00094745  new york   300\n15  2018-01-02T00:00:00  GHCND:USW00094789  new york   260\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Peak gust wind speed (tenths of meters per second)========\nEmpty DataFrame\nColumns: [date, stationid, city, WSFG]\nIndex: []\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Direction of fastest 5-second wind (degrees)========\n                   date          stationid      city  WDF5\n0   2018-01-01T00:00:00  GHCND:USW00014732  new york   300\n1   2018-01-01T00:00:00  GHCND:USW00014734  new york   320\n2   2018-01-01T00:00:00  GHCND:USW00054743  new york   320\n3   2018-01-01T00:00:00  GHCND:USW00054787  new york   310\n4   2018-01-01T00:00:00  GHCND:USW00094728  new york   300\n5   2018-01-01T00:00:00  GHCND:USW00094741  new york   320\n6   2018-01-01T00:00:00  GHCND:USW00094745  new york   310\n7   2018-01-01T00:00:00  GHCND:USW00094789  new york   310\n8   2018-01-02T00:00:00  GHCND:USW00014732  new york   270\n9   2018-01-02T00:00:00  GHCND:USW00014734  new york   270\n10  2018-01-02T00:00:00  GHCND:USW00054743  new york   290\n11  2018-01-02T00:00:00  GHCND:USW00054787  new york   300\n12  2018-01-02T00:00:00  GHCND:USW00094728  new york   250\n13  2018-01-02T00:00:00  GHCND:USW00094741  new york   290\n14  2018-01-02T00:00:00  GHCND:USW00094745  new york   280\n15  2018-01-02T00:00:00  GHCND:USW00094789  new york   270\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Fastest 5-second wind speed (tenths of meters per second)========\n                   date          stationid      city  WSF5\n0   2018-01-01T00:00:00  GHCND:USW00014732  new york   143\n1   2018-01-01T00:00:00  GHCND:USW00014734  new york   143\n2   2018-01-01T00:00:00  GHCND:USW00054743  new york   112\n3   2018-01-01T00:00:00  GHCND:USW00054787  new york   103\n4   2018-01-01T00:00:00  GHCND:USW00094728  new york   112\n5   2018-01-01T00:00:00  GHCND:USW00094741  new york   134\n6   2018-01-01T00:00:00  GHCND:USW00094745  new york   134\n7   2018-01-01T00:00:00  GHCND:USW00094789  new york   152\n8   2018-01-02T00:00:00  GHCND:USW00014732  new york   139\n9   2018-01-02T00:00:00  GHCND:USW00014734  new york   116\n10  2018-01-02T00:00:00  GHCND:USW00054743  new york    98\n11  2018-01-02T00:00:00  GHCND:USW00054787  new york   107\n12  2018-01-02T00:00:00  GHCND:USW00094728  new york   125\n13  2018-01-02T00:00:00  GHCND:USW00094741  new york   116\n14  2018-01-02T00:00:00  GHCND:USW00094745  new york   116\n15  2018-01-02T00:00:00  GHCND:USW00094789  new york   130\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========24-hour wind movement (km)========\nEmpty DataFrame\nColumns: [date, stationid, city, WDMV]\nIndex: []\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Direction of peak wind gust (degrees)========\nEmpty DataFrame\nColumns: [date, stationid, city, WDFG]\nIndex: []\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Average daily wind speed (tenths of meters per second)========\n                   date          stationid      city  AWND\n0   2018-01-01T00:00:00  GHCND:USW00014732  new york    76\n1   2018-01-01T00:00:00  GHCND:USW00014734  new york    57\n2   2018-01-01T00:00:00  GHCND:USW00054743  new york    29\n3   2018-01-01T00:00:00  GHCND:USW00054787  new york    38\n4   2018-01-01T00:00:00  GHCND:USW00094728  new york    35\n5   2018-01-01T00:00:00  GHCND:USW00094741  new york    56\n6   2018-01-01T00:00:00  GHCND:USW00094745  new york    57\n7   2018-01-01T00:00:00  GHCND:USW00094789  new york    79\n8   2018-01-02T00:00:00  GHCND:USW00014732  new york    62\n9   2018-01-02T00:00:00  GHCND:USW00014734  new york    64\n10  2018-01-02T00:00:00  GHCND:USW00054743  new york    31\n11  2018-01-02T00:00:00  GHCND:USW00054787  new york    48\n12  2018-01-02T00:00:00  GHCND:USW00094728  new york    36\n13  2018-01-02T00:00:00  GHCND:USW00094741  new york    50\n14  2018-01-02T00:00:00  GHCND:USW00094745  new york    41\n15  2018-01-02T00:00:00  GHCND:USW00094789  new york    70\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Fastest 2-minute wind speed (tenths of meters per second)========\n                   date          stationid      city  WSF2\n0   2018-01-01T00:00:00  GHCND:USW00014732  new york   112\n1   2018-01-01T00:00:00  GHCND:USW00014734  new york   107\n2   2018-01-01T00:00:00  GHCND:USW00054743  new york    76\n3   2018-01-01T00:00:00  GHCND:USW00054787  new york    72\n4   2018-01-01T00:00:00  GHCND:USW00094728  new york    67\n5   2018-01-01T00:00:00  GHCND:USW00094741  new york    94\n6   2018-01-01T00:00:00  GHCND:USW00094745  new york    98\n7   2018-01-01T00:00:00  GHCND:USW00094789  new york   130\n8   2018-01-02T00:00:00  GHCND:USW00014732  new york    98\n9   2018-01-02T00:00:00  GHCND:USW00014734  new york    94\n10  2018-01-02T00:00:00  GHCND:USW00054743  new york    76\n11  2018-01-02T00:00:00  GHCND:USW00054787  new york    76\n12  2018-01-02T00:00:00  GHCND:USW00094728  new york    72\n13  2018-01-02T00:00:00  GHCND:USW00094741  new york    89\n14  2018-01-02T00:00:00  GHCND:USW00094745  new york    98\n15  2018-01-02T00:00:00  GHCND:USW00094789  new york   103\n\n\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Highest instantaneous wind speed (tenths of meters per second)========\nEmpty DataFrame\nColumns: [date, stationid, city, WSFI]\nIndex: []\n\n\n\n"
     ]
    }
   ],
   "source": [
    "for hitted in intersections:\n",
    "    \n",
    "    named_entity_column = None\n",
    "    for idx, variable in enumerate(hitted[\"_source\"][\"variables\"]):\n",
    "        if variable.get(\"named_entity\", None):\n",
    "            named_entity_column = idx\n",
    "            break\n",
    "    \n",
    "    df = augment.get_dataset(\n",
    "        metadata=hitted[\"_source\"],\n",
    "        constrains={\n",
    "            \"named_entity\": {\n",
    "                named_entity_column: [\"new york\"]\n",
    "            },\n",
    "            \"date_range\": {\n",
    "                \"start\": \"2018-01-01T00:00:00\",\n",
    "                \"end\": \"2018-01-02T23:00:00\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(\"========{}========\".format(hitted[\"_source\"][\"description\"]))\n",
    "    print(df)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do get some datasets related to `wind` from NOAA, how to join with old dataframe?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
